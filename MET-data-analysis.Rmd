First things first, let's 

Import our libraries-

```{r}
library(tidyverse)
library(splines)
library(modelr)
```

And load our data-

```{r}
met_objects <- read_csv("openaccess/MetObjects.csv")
```

Cleaning it up

```{r}
met_objects$AccessionYear <- as.double(substr(met_objects$AccessionYear, 1, 4))
```



Variables that seem like they could possibly be useful for predicting `Is Highlight`

1. `Department`
2. `AccessionYear`
3. `Culture`
4. `Artist End Date`
5. `Artist Gender`
6. `Object Date`
7. `Classification`

I suspect that some of these might be categorical variables with a lot of unique values that we should collapse. 
Let's test that theory by making some data grids


```{r}
unique_department <- data_grid(met_objects, Department)
unique_culture <- data_grid(met_objects, Culture)
unique_classification <- data_grid(met_objects, Classification)
```

Looking the sizes of the data grids using our sidebar, we're going to need to figure out how to collapse unique values in everything except `Department`.

Let's start with culture!

Here's some code that collapses this a bunch- down to about 3,000 unique cultures from 7,300 or so originally.

```{r}
unique_culture[1, "Culture"] <- "Chugach, Native American"  # Fixing the newline character that's in there for some reason.
unique_culture <- unique_culture %>% 
  mutate(Culture_Group = str_extract(Culture, "^[^[,;(]]+")) %>%  # First pattern
  mutate(Culture_Group = ifelse(
    str_detect(Culture_Group, "^(possibly|probably)"),  # Check for either word at start
    str_extract(Culture_Group, "(?<=(possibly|probably)\\s)\\w+"),  # Extract word after either
    Culture_Group  # Keep original if neither
  )) %>%
  mutate(Culture_Group = str_to_title(Culture_Group))
```

Now let's merge this with our original dataframe so that we can filter by top cultures.

```{r}
met_objects <- met_objects %>%
  left_join(unique_culture, "Culture") %>%
  mutate(Culture_Group = as.factor(Culture_Group)) %>%
  mutate(Culture_Group = fct_lump_min(Culture_Group, min = 1000)) 

met_objects %>%
  select(Culture_Group) %>%
  group_by(Culture_Group) %>%
  count() %>%
  arrange(desc(n))
  
```

Okay now let's do classification

It seems like we could filter a bunch by just taking the first word.

```{r}
unique_classification <- unique_classification %>% 
  mutate(Classification_Group = str_extract(Classification, "^[^[-,;(|]]+")) %>%
  mutate(Classification_Group = str_to_title(Classification_Group))
```


```{r}
met_objects <- met_objects %>%
  left_join(unique_classification, "Classification") %>%
  mutate(Classification_Group = as.factor(Classification_Group)) %>%
  mutate(Classification_Group = fct_lump_min(Classification_Group, min = 1000)) 
```

Accession Year is really clean- but object date really isn't. Let's clean it up.


```{r}
met_objects <- met_objects %>%
  mutate(
    parsed_year = `Object Date`,
    parsed_year = if_else(
      str_detect(parsed_year, "\\d{4}"),
      str_extract(parsed_year, "\\d{4}"),
      parsed_year
    ),
    parsed_year = if_else(
      str_detect(parsed_year, "\\d{3}"),
      str_extract(parsed_year, "\\d{3}"),
      parsed_year
    ),
    parsed_year = if_else(
      str_detect(parsed_year, "\\d+\\s*(BCE|CE|BC)"),
      if_else(
        str_detect(parsed_year, "BCE"),
        as.character(-as.numeric(str_extract(parsed_year, "\\d+"))),
        str_extract(parsed_year, "\\d+")
      ),
      parsed_year
    ),
    parsed_year = if_else(
      str_detect(parsed_year, "\\d{1,2}(st|nd|rd|th)"),
      as.character(
        as.numeric(str_extract(parsed_year, "\\d{1,2}")) * 100
      ),
      parsed_year
    ),
    parsed_year = as.numeric(parsed_year)
  )

```

Cleaning Gender

```{r}
met_objects <- met_objects %>%
  mutate(parsed_gender = ifelse(is.na(`Artist Gender`), NA, 
                                ifelse(str_detect(`Artist Gender`, "[Ff]emale"), "Female", "Male")))
```

Messing with the data types to make glm happy and selecting just the variables we need

```{r}
met_objects$Culture_Group <- as.character(met_objects$Culture_Group)
met_objects$Classification_Group <- as.character(met_objects$Classification_Group)
selected_variables <- met_objects %>%
  select(`Is Highlight`, Department, AccessionYear, Culture_Group, parsed_gender, parsed_year, Classification_Group) %>%
  mutate(Department = ifelse(is.na(Department), 'Unknown', Department)) %>%
  mutate(parsed_gender = ifelse(is.na(parsed_gender), 'Unknown', parsed_gender)) %>%
  mutate(Culture_Group = ifelse(is.na(Culture_Group), 'Unknown', Culture_Group)) %>%
  mutate(Classification_Group = ifelse(is.na(Classification_Group), 'Unknown', Classification_Group))
```

Okay now that we've got our data cleaned it's time to answer our questions.

## Question 1: Which variables have the highest correlation with `isHighlight`?

Let's set our seed and split up our model.

```{r}
set.seed(123)
big_met_training <- sample_n(selected_variables, nrow(selected_variables) * 0.8)
big_met_testing <- anti_join(selected_variables, big_met_training)
```

Setting up our baseline model...

```{r}
big_met_testing %>%
  mutate(baseline_prediction = FALSE) %>%
  summarize(sum(baseline_prediction ==`Is Highlight`)/nrow(big_met_testing))
```

Some more data type shenanigans and making the model

```{r}
big_met_training$Culture_Group <- as.character(big_met_training$Culture_Group)
big_met_training$Classification_Group <- as.character(big_met_training$Classification_Group)
big_met_training$Department <- as.character(big_met_training$Department)
big_met_training$parsed_gender <- as.character(big_met_training$parsed_gender)

met_model <- glm(`Is Highlight` ~ Department + AccessionYear + Culture_Group + 
                      parsed_gender + parsed_year + Classification_Group, 
                      data = big_met_training, family='binomial')

met_model
```

Our accuracy rate on the test data

```{r}
big_met_testing %>%
  add_predictions(met_model, type='response') %>%
  mutate(predicted_outcome = ifelse(pred>=0.5, TRUE, FALSE)) %>%
  mutate(is_correct = `Is Highlight` == predicted_outcome) %>%
  summarize(mean(is_correct, na.rm=TRUE))
```

So our model is slightly better than the baseline, since 0.9560013 > 0.95562

This might seem small but over the course of our 484956 observations, the delta between those two (0.9560013-0.95562) will contribute to nearly 185 more correct predictions!

```{r}
(0.9560013-0.95562) * 484956
```


Let's put our coefficients in a dataframe

```{r}
coefficients <- coef(met_model)
coef_data <- data.frame(
  Variable = names(coefficients),
  Coefficient = coefficients
)
coef_data %>%
  arrange(desc(Coefficient))
```

Now let's graph them!

```{r}

coef_data %>%
  mutate(Variable = reorder(Variable, Coefficient)) %>% 
  ggplot() +
  geom_bar(aes(y = Variable, x = Coefficient), stat = "identity")
```

This can also help us answer questions 2 and 3.

Questions 2: If I'm artist and want the Met to think my art is "a popular and important artwork in the collection" what kind of art should I make? What should my demographics be?

The surprising answer is to make sculpture! Stone sculpture in particular is really helpful for getting the Met to think you're cool.

How old you are and when the Met found your art is basically insignificant, and you face a very very minor disadvantage if you're a man.

Most cultures lie somewhere in the middle but you're best off being Japanese, Greek, German or Spanish. I'm pretty skeptical of this though because while Japanese is the highest rated culture, one of the low rated cutures is 'Japan'.

There are quite a few mediums that really hurt your chances—these include Coins, Stucco, Negatives, Albums, Ephemera, Plaquettes, Books, and Jade. 

Somewhat surprisingly you also really don't want to be European—although this seems like an obvious artifact of the Met overprioritizing European art in their collection.

Question 3: What time periods and cultures are the best-represented among the Met's "popular and important artwork".

Time period has basically no impact on whether the art in question is a highlight.

As I mentioned above most cultures don't seem to matter and even the ones that do are suspect.

So if you're an art dealing trying to get the Met to like you I'd focus on stone sculpture.

```{r}
nat_objects <- read_csv("objects.csv")
```


```{r}
nat_objects
```

